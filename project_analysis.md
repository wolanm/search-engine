[toc]

## 项目架构
go-zero, gRPC, k8s, redis, boltdb
TODO: 架构图

## 项目亮点分析
### 索引构建与多路召回
基于倒排索引及向量索引实现多路召回架构，通过引入**BM25相关性预计算**，显著降低搜索阶段的计算负载，提升整体召回效率；运用**Bitmap**优化文档集合的交并操作，并有效压缩倒排索引的存储空间(**平均压缩率50%**)。

#### 召回后的融合
倒排和向量融合: 0.6 * 倒排score + 0.4 * 向量score，倒排权重更多的原因:
1. 知识库文档内容结构化程度高，BM25匹配效果好
2. 为了保障覆盖率

倒排索引返回 20-30 篇文档，向量索引返回 20-25 篇文档

#### BM25
BM25 公式:

```shell
Score(D, Q) = Σ [ IDF(q_i) * ( TF(q_i, D) * (k1 + 1) ) / ( TF(q_i, D) + k1 * (1 - b + b * |D| / avgdl) ) ]
```
* IDF(q_i) - 逆文档频率项 IDF 衡量一个词的普遍重要性。一个词在所有文档中出现的越频繁，其 IDF 值越低。
  IDF(q_i) = log( 1 + (N - n(q_i) + 0.5) / (n(q_i) + 0.5) )
* N：文档集合中的总文档数。
* n(q_i)：包含词项 q_i 的文档数量。
* TF(q_i, D)：词项 q_i 在文档 D 中出现的次数。
* |D|：文档 D 的长度（通常用词数表示）。
* avgdl：整个文档集合中所有文档的平均长度。
* k1：一个可调参数，控制词频的饱和速率。 k1 越大，饱和越慢，词频的影响越大（通常取值在 1.2 到 2.0 之间）。 k1 = 0 意味着完全忽略词频。
* b：另一个可调参数，控制文档长度归一化的强度。
  b 在 0 到 1 之间。
  b = 1 表示 fully normalizing（完全进行长度归一化）。
  b = 0 表示完全不进行长度归一化。

#### bitmap 存储倒排索引
为什么采用 boltdb?
* 好处：
  1. 读取性能好，读取操作是通过 mmap 内存映射完成，适合读多写少的场景
  2. 轻量，部署简单

* 坏处：
  1. 没有主从功能，只能自己实现

压缩率 平均压缩率50%:
```shell
=== SUMMARY REPORT ===
| Case Name           | Set Size | List Size | Roaring Size | Bitset Size | Roaring vs List | Roaring vs Bitset |
|---------------------|----------|-----------|--------------|-------------|------------------|-------------------|
| Very Low Frequency  |       10 |        40 |         108 |    1250008 |         -170.0% |           100.0% |
| Low Frequency       |      100 |       400 |         816 |    1250008 |         -104.0% |            99.9% |
| Medium Frequency    |    10000 |     40000 |       21232 |    1250008 |           46.9% |            98.3% |
| High Frequency      |   100000 |    400000 |      201232 |    1250008 |           49.7% |            83.9% |
| Very High Frequency |  5000000 |  20000000 |     1254608 |    1250008 |           93.7% |            -0.4% |

```


### 分级搜索缓存
基于 **Redis** 构建**用户最近记录**缓存与热点资源（**Hot 50**）缓存。设计并实现了**三级缓存结构**，结合定时衰减策略动态管理热点内容迁移，通过 Redis 实现**分布式锁**保障同一时间只会有一个实例执行衰减任务。

缓存每个用户最近的10条搜索记录，通过 redis 的 List 实现，key 为 recent_query:{user_id}(需要注意去重)

统计hot30: 通过 redis 的 zset 实现，每次搜索时，对搜索语句的分数加 1，并进行缓存迁移，定时进行分数衰减


#### 三层缓存
三层缓存:
* L1: hot30 衰减因子 0.95，每 24h 进行一次衰减
* L2: hot300 衰减因子 0.9，每 12h 进行一次衰减
* L3: 其他 衰减因子 0.8， 每 1h 进行一次衰减
  当分数 < 0.8 时，清除缓存

##### 搜索流程
每一级缓存一把锁
先从本地缓存获取，获取失败则按照 L1->L2->L3 的顺序查询缓存，依次先加读锁，如果 L1 获取到了，则加 L1 的写锁，更新 query 的 score，依次类推。
如果三层缓存都没查到，则执行搜索，同时写入L3缓存，如果搜索无结果，则考虑设置缓存内容为空值，避免缓存击穿

##### 衰减任务和缓存层级迁移任务的创建
由 redis 实例创建，并通过 publish 发送给各搜索副本，各搜索副本收到后开始抢占任务

##### 缓存层级迁移
* 通过 list 实现任务队列，每个搜索副本收到任务创建通知后，尝试抢占并执行任务
* 每个副本都定时轮询任务队列，直到任务队列为空

##### 衰减任务
* 通过 hash 实现一个简易的任务队列，每个副本要执行衰减任务时，会尝试获取任务队列锁，获取成功的开始执行衰减任务 
* 其他副本定时轮询任务队列，如果队列非空且锁空闲，则尝试获取锁继续执行任务，任务队列为空时停止轮询
* 采用redis 管道批量提交方式更新任务执行进度，其它副本接手时继续未完成的任务


#### 本地缓存采用 LRU
TODO: leetcode lru

#### 问题
* 查询语句差一个字可能就会导致查询缓存失效，这种情况如何处理？
  根据语义相似性(向量相似度)处理，相似度 > 0.85 则认为相同

* 文档更新时如何让所有缓存(本地、redis)失效?
  消息队列通知

* LRU 实现 localCache，限制长度、内存大小、过期时间？
  * 限制内存: 机器内存为 8G，留 4G 作为缓存
  * 限制数量: 搜索结果平均长度为 1kb，4G / 1kb ≈ 400 万条
  * 过期时间: L3 缓存的衰减时间间隔，即 1h


* 如何避免缓存击穿、穿透、雪崩?
  TODO:
  缓存击穿:
  1. 对一些无用搜索进行排除: test, 111, 测试等
  2. 对未查询到的搜索缓存空值，且不进行热度评分
     缓存穿透:
     缓存雪崩:

* 倒排的缓存?
  TODO:

* 缓存分布式锁的实现?
  TODO: 细节需要明确 redis setnx + expire + lua

* 为什么不直接在 redis 机器上执行衰减任务、缓存层级迁移任务呢？
  Redis实例重启或故障时，正在执行的Lua脚本会中断，缺乏任务状态持久化和恢复机制

### 消息队列解耦
用法: 收到索引构建请求后，将构建需求(doc_id)发送到 rabbitmq，倒排索引、向量索引及搜索服务同时消费

消息处理的幂等性: 索引服务(倒排、向量)分别通过 redis 缓存 message_id 实现消费的幂等性
message_id 如何设计? uuid + 时间戳

可靠性保证：rabbitmq 的消息确认机制，结合慢重试(通过延迟消息实现，初始重试时间为 1s，通过指数退避增加重试时间，最大重试次数为10次) + 死信队列保证任务构建的可靠性

延迟消息是通过延迟交换机绑定工作队列实现的，超过最大重试次数后放到死信队列

消息堆积：TODO


## 排障经验
TODO

