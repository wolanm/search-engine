[toc]

## 项目架构
go-zero, gRPC, k8s, redis, boltdb
TODO: 架构图

## 项目亮点分析
### 索引构建与多路召回
基于倒排索引及向量索引实现多路召回架构，通过引入**BM25相关性预计算**，显著降低搜索阶段的计算负载，提升整体召回效率；运用**Bitmap**优化文档集合的交并操作，并有效压缩倒排索引的存储空间(**平均压缩率50%**)。

#### 召回后的融合
倒排和向量融合: 0.6 * 倒排score + 0.4 * 向量score，倒排权重更多的原因:
1. 知识库文档内容结构化程度高，BM25匹配效果好
2. 为了保障覆盖率

倒排索引返回 20-30 篇文档，向量索引返回 20-25 篇文档

#### BM25
BM25 公式:

```shell
Score(D, Q) = Σ [ IDF(q_i) * ( TF(q_i, D) * (k1 + 1) ) / ( TF(q_i, D) + k1 * (1 - b + b * |D| / avgdl) ) ]
```
* IDF(q_i) - 逆文档频率项 IDF 衡量一个词的普遍重要性。一个词在所有文档中出现的越频繁，其 IDF 值越低。
  IDF(q_i) = log( 1 + (N - n(q_i) + 0.5) / (n(q_i) + 0.5) )
* N：文档集合中的总文档数。
* n(q_i)：包含词项 q_i 的文档数量。
* TF(q_i, D)：词项 q_i 在文档 D 中出现的次数。
* |D|：文档 D 的长度（通常用词数表示）。
* avgdl：整个文档集合中所有文档的平均长度。
* k1：一个可调参数，控制词频的饱和速率。 k1 越大，饱和越慢，词频的影响越大（通常取值在 1.2 到 2.0 之间）。 k1 = 0 意味着完全忽略词频。
* b：另一个可调参数，控制文档长度归一化的强度。
  b 在 0 到 1 之间。
  b = 1 表示 fully normalizing（完全进行长度归一化）。
  b = 0 表示完全不进行长度归一化。

#### pgSQL bitmap 存储倒排索引?
为什么采用 pgSQL?
* 好处：
  1. 对 bitmap 的存储支持的比较好
  2. 故障转移支持的比较好


压缩率 平均压缩率50%:
```shell
=== SUMMARY REPORT ===
| Case Name           | Set Size | List Size | Roaring Size | Bitset Size | Roaring vs List | Roaring vs Bitset |
|---------------------|----------|-----------|--------------|-------------|------------------|-------------------|
| Very Low Frequency  |       10 |        40 |         108 |    1250008 |         -170.0% |           100.0% |
| Low Frequency       |      100 |       400 |         816 |    1250008 |         -104.0% |            99.9% |
| Medium Frequency    |    10000 |     40000 |       21232 |    1250008 |           46.9% |            98.3% |
| High Frequency      |   100000 |    400000 |      201232 |    1250008 |           49.7% |            83.9% |
| Very High Frequency |  5000000 |  20000000 |     1254608 |    1250008 |           93.7% |            -0.4% |

```

#### 倒排索引采用的是主从服务、读写分离
简单来说，处理主节点宕机的核心逻辑就是：

1. 发现它挂了（通过心跳）。 
2. 找个替身（通过选举，选数据最新的）。 
3. 通知大家新老板是谁（通过服务发现）。 
4. 让业务继续（新主节点开始服务）。
5. 宕机的旧主节点上线时，通过配置中心查询到主节点地址不是自己，变为从节点

### 分级搜索缓存
基于本地 **LFU** 及 **Redis** 构建搜索缓存。设计并实现了 **两级级缓存结构**，结合缓存智能过期、动态调整缓存时间管理热点query。

#### 两级缓存
* L1: 本地采用 LFU
  * hit_count > 3000: ttl = 3h
  * hit_count > 1000: ttl = 1h
  * 其它: ttl = 10min
* L2: 第二级采用 Redis 分布式缓存，通过 zset 管理分词及 hit_count 
  * TTL 设置为 7 天(缓存预热可以解决节假日缓存清空的问题)
  * 需要限制最大数量和内存，最大数量取总词语数量的 50%，内存为 2G

#### 缓存预热
1. 捕获 Top Query： 编写一个简单的脚本，分析 上周五（或过去 7 天）的搜索日志，提取出 Top 1000 ~ 5000 的高频搜索词。 
2. 定时重放： 在 周一早上 7:00 ~ 8:00（业务高峰前），通过脚本模拟请求，向搜索服务发起这几千次查询。 
3. 效果：
   * 这会强制触发后端计算，将结果加载到 L2 Redis 中。 
   * 甚至可以加载到应用节点的 L1 内存中（如果 L1 TTL 设置得当）。 
4. 进阶技巧： 预热时带上特殊的 Header（如 X-Warmup: true），不在日志中统计这些请求，以免污染 BI 数据。

##### 搜索流程
阶段一：请求预处理与 Key 构造
* 对 query 做归一化处理(转小写、去空格等)
* 通过向量索引服务获取 top20 相似度的 query

阶段二：L1 本地缓存检查
* L1 检查：使用 score > 0.9 的 key 在 LFU 中搜索。 
* L1 命中：直接返回 LLM 最终答案。流程结束。 
* L1 未命中： 继续。

阶段三：L2 远程缓存检查
* 根据 score > 0.9 的 query 查找缓存
* 命中：写入 L1，返回答案
* 未命中：继续

阶段四：回源：双路召回与融合排序
* 倒排召回
* 向量召回
* 融合去重

阶段五：文档获取与 LLM 推理
* 根据融合去重后的 id 列表，获取对应的文档内容
* LLM 推理，返回答案

阶段六：缓存回写与同步
* 写入 L1 和 L2，先写 Redis，再写本地。优先保障共享缓存

#### 问题
* 查询语句差一个字可能就会导致查询缓存失效，这种情况如何处理？
  根据语义相似性(向量相似度)处理，相似度 > 0.9 则认为相同

* 文档更新时如何让所有缓存(本地、redis)失效?
  消息队列通知

* 文档 id 的设计？
  * 分为 ExternalID 和 InternalID 
  * ExternalID 是由文档处理模块传递过来的，算法为 uuid + timestamp 生成字符串，再根据内部算法加密
  * InternalID 是倒排索引自建的整数 ID，通过一张表来维护
  * 建立 <ExternalID, InternalID> 的映射
  * 将 bitmap 的 id 分布稠密化

* 文档 id 列表数据量级有多少？
  * 10 万篇文档，去重后大概有 15 万个词
  * 词汇占内存大概 100000 * 50byte ≈ 5MB
  * 每个词大概出现在 150 篇文档中，倒排列表占内存 150000 * 150 * 8 ≈ 170MB
  * 用 bitmap 压缩后大概在 80MB
  * 加上预计算的数据(主要是TF(q_i, D)): 
    * 词项 q_i 在文档D中出现的次数 TF(q_i, D): 与倒排列表差不多，大概 160MB
  * 总计 240MB

* 倒排索引缓存
  * 将查询过的词都缓存起来

* 本地 LFU 和 Redis，限制数量、内存大小、过期时间？
  * 限制内存: 
    * 本地机器内存为 8G，留 512MB 作为缓存
    * Redis 机器内存为 8G，留 4G 作为缓存
  * 限制数量: 
    * 本地 10000 个词
    * Redis 30000-40000个
  * 过期时间: 
    * 本地高频 3h，中频 1h，低频 10min
    * Redis 设置 5 天

* 缓存命中率
  * 本地 30%
  * Redis 70%

* qps
  * 高频 qps 在 3000
  * 平均在 1000

* 缓存预热的细节？从哪里读取日志？搜索词的有效性？预热会不胡影响业务性能？


* 如何避免缓存击穿、穿透、雪崩?
  TODO:
  缓存穿透:
  1. 对一些无用搜索进行排除: test, 111, 测试等
  2. 对未查询到的搜索缓存空值，且不进行热度评分
     缓存击穿: 热 query 的 score 比较高，不会突然过期
     缓存雪崩: 热 query 的 score 比较高，不会突然过期

* 缓存分布式锁的实现?
  TODO: 细节需要明确 redis setnx + expire + lua


### 消息队列解耦
用法: 收到索引构建请求后，将构建需求(doc_id)发送到 rabbitmq，倒排索引、向量索引及搜索服务同时消费

消息处理的幂等性: 索引服务(倒排、向量)分别通过 redis 缓存 message_id 实现消费的幂等性
message_id 如何设计? uuid + 时间戳

可靠性保证：rabbitmq 的消息确认机制，结合慢重试(通过延迟消息实现，初始重试时间为 1s，通过指数退避增加重试时间，最大重试次数为10次) + 死信队列保证任务构建的可靠性

延迟消息是通过延迟交换机绑定工作队列实现的，超过最大重试次数后放到死信队列

慢重试如何实现?

消息堆积：TODO


## 排障经验
TODO

