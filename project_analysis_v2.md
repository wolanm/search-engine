[toc]

## 项目架构
go-zero, gRPC, k8s, redis, boltdb
TODO: 架构图

## 项目亮点分析
### 索引构建与多路召回
基于倒排索引及向量索引实现多路召回架构，通过引入**BM25相关性预计算**，显著降低搜索阶段的计算负载，提升整体召回效率；运用**Bitmap**优化文档集合的交并操作，并有效压缩倒排索引的存储空间(**平均压缩率50%**)。

#### 召回后的融合
倒排和向量融合: 0.6 * 倒排score + 0.4 * 向量score，倒排权重更多的原因:
1. 知识库文档内容结构化程度高，BM25匹配效果好
2. 为了保障覆盖率

倒排索引返回 20-30 篇文档，向量索引返回 20-25 篇文档

#### BM25
BM25 公式:

```shell
Score(D, Q) = Σ [ IDF(q_i) * ( TF(q_i, D) * (k1 + 1) ) / ( TF(q_i, D) + k1 * (1 - b + b * |D| / avgdl) ) ]
```
* IDF(q_i) - 逆文档频率项 IDF 衡量一个词的普遍重要性。一个词在所有文档中出现的越频繁，其 IDF 值越低。
  IDF(q_i) = log( 1 + (N - n(q_i) + 0.5) / (n(q_i) + 0.5) )
* N：文档集合中的总文档数。
* n(q_i)：包含词项 q_i 的文档数量。
* TF(q_i, D)：词项 q_i 在文档 D 中出现的次数。
* |D|：文档 D 的长度（通常用词数表示）。
* avgdl：整个文档集合中所有文档的平均长度。
* k1：一个可调参数，控制词频的饱和速率。 k1 越大，饱和越慢，词频的影响越大（通常取值在 1.2 到 2.0 之间）。 k1 = 0 意味着完全忽略词频。
* b：另一个可调参数，控制文档长度归一化的强度。
  b 在 0 到 1 之间。
  b = 1 表示 fully normalizing（完全进行长度归一化）。
  b = 0 表示完全不进行长度归一化。

#### pgSQL bitmap 存储倒排索引?
为什么采用 pgSQL?
* 好处：
  1. 对 bitmap 的存储支持的比较好
  2. 故障转移支持的比较好


压缩率 平均压缩率50%:
```shell
=== SUMMARY REPORT ===
| Case Name           | Set Size | List Size | Roaring Size | Bitset Size | Roaring vs List | Roaring vs Bitset |
|---------------------|----------|-----------|--------------|-------------|------------------|-------------------|
| Very Low Frequency  |       10 |        40 |         108 |    1250008 |         -170.0% |           100.0% |
| Low Frequency       |      100 |       400 |         816 |    1250008 |         -104.0% |            99.9% |
| Medium Frequency    |    10000 |     40000 |       21232 |    1250008 |           46.9% |            98.3% |
| High Frequency      |   100000 |    400000 |      201232 |    1250008 |           49.7% |            83.9% |
| Very High Frequency |  5000000 |  20000000 |     1254608 |    1250008 |           93.7% |            -0.4% |

```

#### 倒排索引采用的是主从服务、读写分离
简单来说，处理主节点宕机的核心逻辑就是：

1. 发现它挂了（通过心跳）。 
2. 找个替身（通过选举，选数据最新的）。 
3. 通知大家新老板是谁（通过服务发现）。 
4. 让业务继续（新主节点开始服务）。
5. 宕机的旧主节点上线时，通过配置中心查询到主节点地址不是自己，变为从节点

### 分级搜索缓存
基于本地 **LFU** 及 **Redis** 构建倒排索引热点分词缓存。设计并实现了 **两级级缓存结构**，结合缓存智能过期、动态调整缓存时间管理热点词。

#### 两级缓存
* L1: 本地采用 LFU
* L2: 第二级采用 Redis 分布式缓存，通过 zset 管理分词及 hit_count
* 缓存时间动态调整: 根据 hit_count 设置 ttl
  * hit_count > 3000: ttl = 6h
  * hit_count > 1000: ttl = 2h
  * 其它: ttl = 30min
  * 本地缓存打半折


##### 搜索流程
先从本地缓存获取，获取失败则查询分布式缓存，如果获取到了，更新本地缓存及 redis
如果没查到，则执行搜索，将结果更新缓存，如果搜索结果为空，则考虑设置缓存内容为空值，避免缓存穿透

#### 问题
* 查询语句差一个字可能就会导致查询缓存失效，这种情况如何处理？
  根据语义相似性(向量相似度)处理，相似度 > 0.85 则认为相同

* 文档更新时如何让所有缓存(本地、redis)失效?
  消息队列通知

* 文档 id 的设计？

* 文档 id 列表数据量级有多少？

* LFU 实现 localCache，限制长度、内存大小、过期时间？
  * 限制内存: 机器内存为 8G，留 1G 作为缓存
  * 限制数量: 10000 个词
  * 过期时间: redis 的一半


* 如何避免缓存击穿、穿透、雪崩?
  TODO:
  缓存穿透:
  1. 对一些无用搜索进行排除: test, 111, 测试等
  2. 对未查询到的搜索缓存空值，且不进行热度评分
     缓存击穿: 热词的 score 比较高，不会突然过期
     缓存雪崩: 热词的 score 比较高，不会突然过期

* 缓存分布式锁的实现?
  TODO: 细节需要明确 redis setnx + expire + lua


### 消息队列解耦
用法: 收到索引构建请求后，将构建需求(doc_id)发送到 rabbitmq，倒排索引、向量索引及搜索服务同时消费

消息处理的幂等性: 索引服务(倒排、向量)分别通过 redis 缓存 message_id 实现消费的幂等性
message_id 如何设计? uuid + 时间戳

可靠性保证：rabbitmq 的消息确认机制，结合慢重试(通过延迟消息实现，初始重试时间为 1s，通过指数退避增加重试时间，最大重试次数为10次) + 死信队列保证任务构建的可靠性

延迟消息是通过延迟交换机绑定工作队列实现的，超过最大重试次数后放到死信队列

消息堆积：TODO


## 排障经验
TODO

